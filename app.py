import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
import time  # ë”œë ˆì´ ì¶”ê°€
import google.generativeai as genai  # Google Generative AI ì¶”ê°€
import random  # ëœë¤ ì„ íƒ ì¶”ê°€
import re  # ìˆ«ì ì¶”ì¶œì„ ìœ„í•œ ì •ê·œ í‘œí˜„ì‹ ì¶”ê°€

# Google Gemini API ì„¤ì •
API_KEY = "AIzaSyDmaCsKCS4PrE3B-ErmHKknXEOpHQ2vjno"  # Google Generative AI í‚¤
genai.configure(api_key=API_KEY)

# CSS ì¶”ê°€
st.markdown("""
    <style>
        .title {
            font-size: 50px;
            font-weight: bold;
            color: white; /* ì´ˆë¡ìƒ‰ ê¸€ì”¨ */
            text-align: center; /* ì œëª©ì„ ê°€ìš´ë° ì •ë ¬ */
        }
.subtitle {
    font-size: 12px;
    color: #FFFFFF; /* ê¸€ììƒ‰ì„ í™”ì´íŠ¸ë¡œ ì„¤ì • */
    text-align: right; /* ê¸€ì”¨ë¥¼ ì˜¤ë¥¸ìª½ ì •ë ¬ */
    float: right; /* ìƒìë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™ */
    margin-top: 30px; /* ìƒë‹¨ ì—¬ë°± ì¶”ê°€ */
    margin-bottom: 20px /* í•˜ë‹¨ ì—¬ë°± ì¶”ê°€*/

}


      .stButton > button {
            float: right;
            background-color: #28a745; /* ì´ˆë¡ìƒ‰ ë°°ê²½ */
            color: #FFFFFF !important; /* ë²„íŠ¼ í…ìŠ¤íŠ¸ ìƒ‰ìƒ í°ìƒ‰ */
            font-weight: bold;
            border: none;
            padding: 10px 20px;
            border-radius: 5px; /* ë²„íŠ¼ ëª¨ì„œë¦¬ë¥¼ ë‘¥ê¸€ê²Œ */
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2); /* ê·¸ë¦¼ì ì¶”ê°€ */
            cursor: pointer;
        }
        .stButton > button:hover {
            background-color: #218838; /* ë²„íŠ¼ í˜¸ë²„ì‹œ ìƒ‰ìƒ ë³€ê²½ */
        }

                .input-label {
            font-size: 22px; /* ê¸€ì”¨ í¬ê¸° ì„¤ì • */
            color: #fffff; /* ì§„í•œ íšŒìƒ‰ */
        }

        .stTextInput > div {
        margin-top: -20px; /* ì…ë ¥ ìƒìì™€ ë ˆì´ë¸” ì‚¬ì´ ì—¬ë°± ê°ì†Œ */
    }

    .stTextArea > div, .stTextInput > div {
        margin-top: -20px; /* ì…ë ¥ í•„ë“œ ìƒë‹¨ ì—¬ë°± ì¤„ì„ */
    }
        .stTextArea, .stTextInput {
        margin-bottom: 30px; /* ì…ë ¥ í•„ë“œ ì‚¬ì´ ê°„ê²© */
    }

    

        
    </style>

""", unsafe_allow_html=True)



# ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_naver_news(keyword):
    encoded_keyword = quote(keyword)
    url = f"https://search.naver.com/search.naver?where=news&query={encoded_keyword}"
    
    # User-Agent ë° Referer ì¶”ê°€
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://www.naver.com"
    }

    try:
        time.sleep(1)
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, "html.parser")
            news_list = []

            # ë‰´ìŠ¤ ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
            for news_item in soup.select("a.news_tit"):
                title = news_item.get("title")
                link = news_item.get("href")
                news_list.append({"title": title, "link": link})

            return news_list[:5]  # ìƒìœ„ 5ê°œ ë‰´ìŠ¤ë§Œ ë°˜í™˜
        else:
            st.error(f"ë„¤ì´ë²„ ë‰´ìŠ¤ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
            return []
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# AI ìš”ì•½ ê°œìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
def extract_summary_count(user_question):
    match = re.search(r'(\d+)', user_question)
    if match:
        return int(match.group(1))
    return 2

# Google Generative AI ìš”ì•½ í•¨ìˆ˜ (ëŒ€í™” í˜•ì‹)
def generate_ai_summary(selected_articles, user_question, keyword):
    """
    Google Generative AIë¥¼ ì‚¬ìš©í•´ ì„ íƒëœ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    combined_data = "\n".join(
        [f"ì œëª©: {article['title']}, ë§í¬: {article['link']}" for article in selected_articles]
    )
    prompt = f"""
    ë‹¤ìŒì€ '{keyword}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ëœ ë‰´ìŠ¤ ì¤‘ ì„ íƒëœ ê¸°ì‚¬ ëª©ë¡ì…ë‹ˆë‹¤:

    {combined_data}

    ìœ„ ë‰´ìŠ¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.  
    ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ê³ , ë‰´ìŠ¤ ìš”ì•½ì„ ê°ê° "ì²« ë²ˆì§¸ ë‰´ìŠ¤ ìš”ì•½ì€", "ë‘ ë²ˆì§¸ ë‰´ìŠ¤ ìš”ì•½ì€" í˜•ì‹ìœ¼ë¡œ ë‚˜ëˆ  ì „ë‹¬í•´ ì£¼ì„¸ìš”.  
    ì˜ˆì‹œ:  
    ğŸ¯ì²« ë²ˆì§¸ ë‰´ìŠ¤ëŠ” ë¹„íŠ¸ì½”ì¸ì˜ ê°€ê²© ìƒìŠ¹ ì†Œì‹ì´ì—ìš”. íˆ¬ììë“¤ì´ ì£¼ëª©í•˜ê³  ìˆë„¤ìš”.  
    ğŸ¯ë‘ ë²ˆì§¸ ë‰´ìŠ¤ëŠ” ë¹„íŠ¸ì½”ì¸ì˜ ì‹œì¥ ë™í–¥ì— ê´€í•œ ê¸°ì‚¬ë„¤ìš”. ì‹ ì¤‘í•˜ê²Œ ì ‘ê·¼í•˜ë¼ëŠ” ì „ë¬¸ê°€ ì˜ê²¬ë„ ìˆì–´ìš”.  
    """
    try:
        model = genai.GenerativeModel("gemini-pro")
        response = model.generate_content(prompt)
        if hasattr(response, 'text'):
            return response.text
        else:
            return "ìœ íš¨í•œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        st.error(f"AI ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# Streamlit UI ì œëª© ë° ì„œë¸Œí…ìŠ¤íŠ¸ í‘œì‹œ
st.markdown('<div class="title">ğŸ“° ë‰´ìŠ¤í•œì…</div>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í¬ë¡¤ë§í•˜ê³ <br>AIë¥¼ ì‚¬ìš©í•´ í•œì… ì‚¬ì´ì¦ˆë¡œ ìš”ì•½í•´ ë“œë¦½ë‹ˆë‹¤~!</div>', unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥
# ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥
st.markdown('<div class="input-label">ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.</div>', unsafe_allow_html=True)
search_keyword = st.text_input(" ", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

# AI ì§ˆë¬¸ ì…ë ¥
st.markdown('<div class="input-label">ğŸ—£ AIì—ê²Œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.</div>', unsafe_allow_html=True)
user_question = st.text_area(" ", placeholder="ì˜ˆ: 'ë‰´ìŠ¤ ìš”ì•½ 2ê°œ í•´ì¤˜'")

if st.button("ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìš”ì•½"):
    if search_keyword and user_question:
        with st.spinner(f"ğŸ”— '{search_keyword}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            news = crawl_naver_news(search_keyword)

        if news:
            st.subheader(f"ğŸ” '{search_keyword}' ë‰´ìŠ¤ ëª©ë¡ (ìµœëŒ€ 10ê°œ)")
            for idx, article in enumerate(news):
                st.write(f"{idx+1}. [{article['title']}]({article['link']})")

            # ì§ˆë¬¸ì—ì„œ ìš”ì•½í•  ë‰´ìŠ¤ ê°œìˆ˜ ì¶”ì¶œ
            num_summary = extract_summary_count(user_question)
            num_summary = min(num_summary, len(news))

            # ë‰´ìŠ¤ì—ì„œ ëœë¤ìœ¼ë¡œ ì„ íƒ
            selected_news = random.sample(news, num_summary)

            st.subheader(f"ğŸ¯ ìš”ì•½í•  ë‰´ìŠ¤ ({num_summary}ê°œ)")
            for idx, article in enumerate(selected_news):
                st.write(f"{idx+1}. [{article['title']}]({article['link']})")

            # AI ìš”ì•½ ìƒì„±
            with st.spinner("ğŸ¤– AIê°€ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤..."):
                summary = generate_ai_summary(selected_news, user_question, search_keyword)

            # ìš”ì•½ ê²°ê³¼ ì¶œë ¥
            st.subheader("ğŸ¤– AI ìš”ì•½ ê²°ê³¼")
            st.write(summary)
        else:
            st.error(f"âŒ '{search_keyword}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        st.warning("í‚¤ì›Œë“œì™€ ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”!")
